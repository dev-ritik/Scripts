{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Tag and categorize the historical expenses from splitwise\n",
    "The expense data is cached locally in expenses.json.\n",
    "The tags are stored locally in tags.json in the form of\n",
    "{\n",
    "  \"wants\": [\n",
    "                str,\n",
    "                {\n",
    "                  \"keyword\": str,\n",
    "                  \"comment\": str,\n",
    "                  \"match_word\": true,\n",
    "                  \"match_case\": false,\n",
    "                  \"ignore_id\": [list of expense id to ignore for this],\n",
    "                  \"include_id\": [list of expense id to include for this]\n",
    "                },\n",
    "           ]\n",
    "}\n",
    "PS: There's no ML. Its just honest labour to categorize based on ones own thoughts\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import dotenv\n",
    "import pytz\n",
    "import requests\n",
    "from dateutil.parser import parse\n",
    "\n",
    "from utils import get_unique_by_key\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "BASE_URL = \"https://secure.splitwise.com/api/v3.0/get_expenses\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {os.getenv('SPLITWISE_TOKEN')}\"}\n",
    "\n",
    "\n",
    "def fetch_expenses(start_date, end_date, limit=200):\n",
    "    params = {\n",
    "        \"dated_after\": start_date.isoformat() + \"Z\",\n",
    "        \"dated_before\": end_date.isoformat() + \"Z\",\n",
    "        \"limit\": limit,\n",
    "    }\n",
    "    response = requests.get(BASE_URL, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()  # Ensure no enigmatic errors\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "# Embark on fetching data in monthly batches\n",
    "def get_all_expenses(_start_date, _end_date):\n",
    "    cached_expenses = read_from_file()\n",
    "    oldest_expenses = max(cached_expenses, key=lambda x: parse(x[\"date\"])) if len(cached_expenses) > 0 else None\n",
    "    _start_date = parse(oldest_expenses[\"date\"]) + timedelta(seconds=1) if oldest_expenses else _start_date\n",
    "    _all_expenses = cached_expenses\n",
    "    while _start_date <= _end_date:\n",
    "        next_date = _start_date + timedelta(days=30)  # Fetch monthly\n",
    "        print(f\"Fetching expenses from {_start_date=} to {next_date}...\")\n",
    "        try:\n",
    "            monthly_expenses = fetch_expenses(_start_date, next_date)\n",
    "            _all_expenses.extend(monthly_expenses.get(\"expenses\", []))\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching data: {e}\")\n",
    "            break\n",
    "        _start_date = next_date + timedelta(seconds=1)\n",
    "\n",
    "    return get_unique_by_key(_all_expenses, key=\"id\")\n",
    "\n",
    "\n",
    "# Save the combined mosaic to a JSON file\n",
    "def save_to_file(data, filename=\"expenses.json\"):\n",
    "    data = sorted(data, key=lambda x: x[\"date\"])\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "\n",
    "# Read the verdant data back from the file\n",
    "def read_from_file(filename=\"expenses.json\"):\n",
    "    if not os.path.exists(filename):\n",
    "        return []\n",
    "    with open(filename, \"r\") as file:\n",
    "        return json.load(file)\n"
   ],
   "id": "f998e6a93efc8675",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "START_DATE = datetime(2022, 4, 1, tzinfo=pytz.timezone(\"Asia/Kolkata\"))\n",
    "END_DATE = datetime(2025, 7, 31, tzinfo=pytz.timezone(\"Asia/Kolkata\"))\n",
    "all_expenses = get_all_expenses(_start_date=START_DATE, _end_date=END_DATE)"
   ],
   "id": "4573119b0ec616ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(all_expenses)",
   "id": "319a549e4bc2ebe3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "save_to_file(all_expenses)",
   "id": "b36acf9eea693d03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verify by reading back\n",
    "loaded_expenses = read_from_file()\n",
    "len(loaded_expenses)"
   ],
   "id": "fef6d58a6aac78e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dateutil import parser, tz\n",
    "from typing import Optional\n",
    "from requests import HTTPError\n",
    "\n",
    "USER_ID: Optional[str] = None\n",
    "\n",
    "\n",
    "def get_user_id() -> str:\n",
    "    \"\"\"\n",
    "    Get the splitwise user id\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global USER_ID\n",
    "\n",
    "    if USER_ID:\n",
    "        return USER_ID\n",
    "\n",
    "    url = \"https://secure.splitwise.com/api/v3.0/get_current_user\"\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {os.getenv(\"SPLITWISE_TOKEN\")}'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data={})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        USER_ID = response.json()[\"user\"][\"id\"]\n",
    "    else:\n",
    "        raise HTTPError(f'Invalid Notion response {response.status_code} {response.text}', response=response)\n",
    "\n",
    "    return USER_ID\n",
    "\n",
    "\n",
    "items = []\n",
    "for item in loaded_expenses:\n",
    "    created = parser.parse(item['date'])\n",
    "    deleted = item['deleted_at']\n",
    "    name = item['description'].strip()\n",
    "    if deleted:\n",
    "        continue\n",
    "\n",
    "    if name == 'Payment':\n",
    "        continue\n",
    "    if name == 'Settle all balances':\n",
    "        continue\n",
    "    created = created.astimezone(tz.tzlocal())\n",
    "    result = {\n",
    "        \"id\": item[\"id\"],\n",
    "        \"date\": created.strftime(\"%Y-%m-%d\"),\n",
    "        \"name\": name\n",
    "    }\n",
    "    for user in item['users']:\n",
    "        if user['user_id'] == get_user_id():\n",
    "            result[\"cost\"] = float(user['owed_share'].strip())\n",
    "            items.append(result)"
   ],
   "id": "4944761229e5ad42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "len(items)\n",
    "items[0]"
   ],
   "id": "ed60febfe16e65ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "all_expense_names_count = defaultdict(int)\n",
    "for item in items:\n",
    "    all_expense_names_count[item['name'].lower()] += 1\n",
    "dict(sorted(all_expense_names_count.items(), key=lambda item: -item[1]))"
   ],
   "id": "fc084cddbfff23a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "TAG_MAPPING = None\n",
    "\n",
    "\n",
    "def get_tags():\n",
    "    global TAG_MAPPING\n",
    "\n",
    "    if TAG_MAPPING:\n",
    "        return TAG_MAPPING\n",
    "\n",
    "    TAG_MAPPING = read_from_file('tags.json') or {}\n",
    "    return TAG_MAPPING\n",
    "\n",
    "\n",
    "def tag_expense(expense_name, _id):\n",
    "    \"\"\"\n",
    "    Assign tags to an expense based on its name.\n",
    "\n",
    "    Args:\n",
    "        expense_name (str): The name of the expense.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tags that match the expense.\n",
    "    \"\"\"\n",
    "    tags = []\n",
    "\n",
    "    for tag, keywords in get_tags().items():\n",
    "        char_match = [keyword for keyword in keywords if isinstance(keyword, str)]\n",
    "        if any(re.search(keyword.lower(), expense_name.lower()) for keyword in char_match):\n",
    "            tags.append(tag)\n",
    "            continue\n",
    "\n",
    "        # Structured matches (dict)\n",
    "        for kw in [k for k in keywords if isinstance(k, dict)]:\n",
    "            pattern = kw[\"keyword\"]\n",
    "            word_match = kw.get(\"match_word\", False)\n",
    "            case_sensitive = kw.get(\"match_case\", False)\n",
    "            ignore_id = kw.get(\"ignore_id\", [])\n",
    "            include_id = kw.get(\"include_id\", [])\n",
    "\n",
    "            if _id in ignore_id:\n",
    "                continue\n",
    "\n",
    "            if include_id and _id not in include_id:\n",
    "                continue\n",
    "\n",
    "            if not case_sensitive:\n",
    "                pattern = pattern.lower()\n",
    "                expense_name = expense_name.lower()\n",
    "\n",
    "            if word_match:\n",
    "                regex = rf\"\\b{re.escape(pattern)}\\b\"\n",
    "            else:\n",
    "                regex = re.escape(pattern)\n",
    "\n",
    "            # print(regex, expense_name)\n",
    "            if re.search(regex, expense_name):\n",
    "                tags.append(tag)\n",
    "                break\n",
    "\n",
    "    return tags if tags else [\"other\"]\n",
    "    # return tags"
   ],
   "id": "9c16a9d20c3d0072",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unclassified = defaultdict(int)\n",
    "\n",
    "for expense in items:\n",
    "    # if not expense[\"name\"] == \"Rent\":\n",
    "    #     continue\n",
    "    tags = tag_expense(expense[\"name\"], expense[\"id\"])\n",
    "    if not tags or tags == [\"other\"]:\n",
    "        print(expense)\n",
    "        unclassified[expense['name']] += 1\n",
    "    expense[\"tags\"] = tags\n",
    "\n",
    "dict(sorted(unclassified.items(), key=lambda item: -item[1]))\n",
    "unclassified.keys()"
   ],
   "id": "aa5dafa08a9f3cfd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sorted([expense for expense in items if \"trip\" in expense[\"tags\"] and expense[\"date\"].startswith(\"2024-04\")],\n",
    "       key=lambda item: -item[\"cost\"])"
   ],
   "id": "b159ea823e706d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(sum([expense['cost'] for expense in items if \"trip\" in expense[\"tags\"] and expense[\"date\"].startswith(\"2024-04\")]))",
   "id": "9b1ba09308196754",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(items)\n",
    "\n",
    "# Parse dates and extract the month\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "df = df.explode('tags')\n",
    "monthly_data = df.groupby(['month', 'tags'])['cost'].sum().reset_index()\n",
    "pivot_data = monthly_data.pivot(index='month', columns='tags', values='cost').fillna(0)\n",
    "pivot_data"
   ],
   "id": "2ac02ff8ee3092d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pivot_data.drop(columns=['other', 'ignore'], inplace=True)",
   "id": "1b7740bc3d125ca6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Optionally remove extreme outliers. Caution: This will lead to data loss but will print better charts\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the 95th percentile for all data and cap values above the threshold\n",
    "threshold = np.quantile(pivot_data.values.flatten(), 0.99)\n",
    "print(f\"Modifying any value above {threshold:.2f} to {threshold:.2f}. Cells that will be capped:\")\n",
    "for row_label, row in pivot_data.iterrows():\n",
    "    for col_label, value in row.items():\n",
    "        if value > threshold:\n",
    "            print(f\"  Row: {row_label}, Column: {col_label}, Value: {value}\")\n",
    "pivot_data = pivot_data.clip(upper=threshold)"
   ],
   "id": "eb374f6d0a31c5b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "plt.figure(figsize=(15, 9), dpi=300)\n",
    "\n",
    "# Smoothen different columns differently based on their name.\n",
    "smoothing_sigma = {\n",
    "    'needs': 2.5,\n",
    "    'parents': 2.5,\n",
    "    'trip': 2,\n",
    "}\n",
    "\n",
    "for tag in pivot_data.columns:\n",
    "    # Apply Gaussian smoothing to emulate smooth curves. Kinda like weighted moving average.\n",
    "    sigma = smoothing_sigma.get(tag, 1.5)  # fallback to sigma=2 if not specified\n",
    "    smoothed_y = gaussian_filter1d(pivot_data[tag], sigma=sigma)\n",
    "\n",
    "    # Plot the smoothed data\n",
    "    plt.plot(pivot_data.index.to_timestamp(), smoothed_y, label=tag)\n",
    "\n",
    "plt.title('Monthly Aggregate Cost')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Cost')\n",
    "plt.legend(title='Tags')\n",
    "plt.minorticks_on()\n",
    "# Major grid (less frequent, light gray)\n",
    "plt.grid(which='major', linestyle='-', linewidth=0.6, alpha=0.75)\n",
    "\n",
    "# Minor grid (more frequent, even lighter)\n",
    "plt.grid(which='minor', linestyle=':', linewidth=0.45, alpha=0.45)\n",
    "# plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"transactions.png\", dpi=300)\n",
    "plt.show()"
   ],
   "id": "f6a25423ac39efd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
