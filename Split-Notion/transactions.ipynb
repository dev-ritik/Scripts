{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Tag and categorize the historical expenses from splitwise\n",
    "The expense data is cached locally in expenses.json.\n",
    "The tags are stored locally in tags.json in the form of\n",
    "{\n",
    "  \"wants\": [<list of str of expense names in lower case>]\n",
    "}\n",
    "PS: There's no ML. Its just honest labour to categorize based on ones own thoughts\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import dotenv\n",
    "import requests\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "BASE_URL = \"https://secure.splitwise.com/api/v3.0/get_expenses\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {os.getenv('SPLITWISE_TOKEN')}\"}\n",
    "\n",
    "\n",
    "def fetch_expenses(start_date, end_date, limit=200):\n",
    "    params = {\n",
    "        \"dated_after\": start_date.isoformat() + \"Z\",\n",
    "        \"dated_before\": end_date.isoformat() + \"Z\",\n",
    "        \"limit\": limit,\n",
    "    }\n",
    "    response = requests.get(BASE_URL, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()  # Ensure no enigmatic errors\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "# Embark on fetching data in monthly batches\n",
    "def get_all_expenses():\n",
    "    start_date = datetime(2022, 4, 1)\n",
    "    end_date = datetime(2025, 1, 10)\n",
    "    all_expenses = []\n",
    "\n",
    "    while start_date < end_date:\n",
    "        next_date = start_date + timedelta(days=30)  # Fetch monthly\n",
    "        print(f\"Fetching expenses from {start_date} to {next_date}...\")\n",
    "        try:\n",
    "            monthly_expenses = fetch_expenses(start_date, next_date)\n",
    "            all_expenses.extend(monthly_expenses.get(\"expenses\", []))\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching data: {e}\")\n",
    "            break\n",
    "        start_date = next_date\n",
    "\n",
    "    return all_expenses\n",
    "\n",
    "\n",
    "# Save the combined mosaic to a JSON file\n",
    "def save_to_file(data, filename=\"expenses.json\"):\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "\n",
    "# Read the verdant data back from the file\n",
    "def read_from_file(filename=\"expenses.json\"):\n",
    "    with open(filename, \"r\") as file:\n",
    "        return json.load(file)\n"
   ],
   "id": "f998e6a93efc8675",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_expenses = get_all_expenses()",
   "id": "4573119b0ec616ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(all_expenses)",
   "id": "319a549e4bc2ebe3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "save_to_file(all_expenses)",
   "id": "b36acf9eea693d03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verify by reading back\n",
    "loaded_expenses = read_from_file()\n",
    "len(loaded_expenses)"
   ],
   "id": "fef6d58a6aac78e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dateutil import parser, tz\n",
    "from typing import Optional\n",
    "from requests import HTTPError\n",
    "\n",
    "USER_ID: Optional[str] = None\n",
    "\n",
    "\n",
    "def get_user_id() -> str:\n",
    "    \"\"\"\n",
    "    Get the splitwise user id\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global USER_ID\n",
    "\n",
    "    if USER_ID:\n",
    "        return USER_ID\n",
    "\n",
    "    url = \"https://secure.splitwise.com/api/v3.0/get_current_user\"\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {os.getenv(\"SPLITWISE_TOKEN\")}'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data={})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        USER_ID = response.json()[\"user\"][\"id\"]\n",
    "    else:\n",
    "        raise HTTPError(f'Invalid Notion response {response.status_code} {response.text}', response=response)\n",
    "\n",
    "    return USER_ID\n",
    "\n",
    "\n",
    "items = []\n",
    "for item in loaded_expenses:\n",
    "    created = parser.parse(item['date'])\n",
    "    deleted = item['deleted_at']\n",
    "    name = item['description'].strip()\n",
    "    if deleted:\n",
    "        continue\n",
    "\n",
    "    if name == 'Payment':\n",
    "        continue\n",
    "    if name == 'Settle all balances':\n",
    "        continue\n",
    "    created = created.astimezone(tz.tzlocal())\n",
    "    result = {\n",
    "        \"date\": created.strftime(\"%Y-%m-%d\"),\n",
    "        \"name\": name\n",
    "    }\n",
    "    for user in item['users']:\n",
    "        if user['user_id'] == get_user_id():\n",
    "            result[\"cost\"] = float(user['owed_share'].strip())\n",
    "            items.append(result)"
   ],
   "id": "4944761229e5ad42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(items)",
   "id": "ed60febfe16e65ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "all_expense_names_count = defaultdict(int)\n",
    "for item in items:\n",
    "    all_expense_names_count[item[1].lower()] += 1\n",
    "dict(sorted(all_expense_names_count.items(), key=lambda item: -item[1]))"
   ],
   "id": "fc084cddbfff23a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "TAG_MAPPING = None\n",
    "\n",
    "\n",
    "def get_tags():\n",
    "    global TAG_MAPPING\n",
    "\n",
    "    if TAG_MAPPING:\n",
    "        return TAG_MAPPING\n",
    "\n",
    "    TAG_MAPPING = read_from_file('tags.json') or {}\n",
    "    return TAG_MAPPING\n",
    "\n",
    "\n",
    "def tag_expense(expense_name):\n",
    "    \"\"\"\n",
    "    Assign tags to an expense based on its name.\n",
    "\n",
    "    Args:\n",
    "        expense_name (str): The name of the expense.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tags that match the expense.\n",
    "    \"\"\"\n",
    "    tags = []\n",
    "    lower_name = expense_name.lower()\n",
    "\n",
    "    for tag, keywords in get_tags().items():\n",
    "        if any(re.search(keyword.lower(), lower_name) for keyword in keywords):\n",
    "            tags.append(tag)\n",
    "\n",
    "    return tags if tags else [\"other\"]\n",
    "    # return tags"
   ],
   "id": "9c16a9d20c3d0072",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "# unclassified = defaultdict(int)\n",
    "for expense in items:\n",
    "    tags = tag_expense(expense[\"name\"])\n",
    "    # if not tags:\n",
    "        # print(expense)\n",
    "    expense[\"tags\"] = tags\n",
    "        # unclassified[expense[1]] += 1\n",
    "\n",
    "# dict(sorted(unclassified.items(), key=lambda item: -item[1]))\n",
    "# unclassified.keys()"
   ],
   "id": "aa5dafa08a9f3cfd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(items)\n",
    "\n",
    "# Parse dates and extract the month\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "df = df.explode('tags')\n",
    "monthly_data = df.groupby(['month', 'tags'])['cost'].sum().reset_index()\n",
    "pivot_data = monthly_data.pivot(index='month', columns='tags', values='cost').fillna(0)\n",
    "pivot_data"
   ],
   "id": "2ac02ff8ee3092d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the 95th percentile for all data and cap values above the threshold\n",
    "threshold = np.quantile(pivot_data.values.flatten(), 0.95)\n",
    "capped_data = pivot_data.clip(upper=threshold)"
   ],
   "id": "eb374f6d0a31c5b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "plt.figure(figsize=(15, 9))\n",
    "\n",
    "for tag in capped_data.columns:\n",
    "    # Apply Gaussian smoothing to emulate smooth curves\n",
    "    smoothed_y = gaussian_filter1d(capped_data[tag], sigma=2)\n",
    "\n",
    "    # Plot the smoothed data\n",
    "    plt.plot(capped_data.index.to_timestamp(), smoothed_y, label=tag)\n",
    "\n",
    "plt.title('Monthly Aggregate Cost')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Cost')\n",
    "plt.legend(title='Tags')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f6a25423ac39efd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "capped_data",
   "id": "8c886b8f4b769d39",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
